{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import dotenv\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "azure_credential = azure.identity.AzureDeveloperCliCredential(tenant_id=os.getenv(\"AZURE_TENANT_ID\"))\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"gptkbindex\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"I want to buy iphone 15\"\n",
    "user_question_vector = get_embedding(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve matching documents\n",
    "\n",
    "The search call below does a **hybrid search**, performing both a full-text search and a vector search in parallel.\n",
    "It merges those results using Reciprocal Rank Fusion (RRF). \n",
    "Finally, it re-ranks the merged results using the AI Search semantic ranker, a re-ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products.txt: Apple iPhone, $1099.00, Apple iPhones are renowned for their premium build quality and seamless integration with the Apple ecosystem. They feature high-resolution Retina displays, powerful A-series processors, and advanced camera systems with features like Night mode and Deep Fusion. iPhones run on iOS, which is known for its smooth performance, security, and a vast selection of apps.\n",
      "\n",
      "\n",
      "products.txt: HP, $799.00, HP laptops are versatile and reliable, with a range of options from budget-friendly to high-end models.\n",
      "\n",
      "\n",
      "products.txt: HP Laptop, $799.00, HP laptops are versatile and reliable, with a range of options from budget-friendly to high-end models. They are equipped with the latest technology, including fast processors, ample storage, and high-quality graphics, making them ideal for both work and play.\n",
      "\n",
      "\n",
      "products.txt: Samsung Smartphone, $999.00, Samsung smartphones are known for their cutting-edge technology and innovative features. They offer high-resolution displays, powerful processors, and advanced camera systems, making them ideal for photography, gaming, and productivity. Samsung's One UI provides a smooth and intuitive user experience, with regular updates and security patches.\n",
      "\n",
      "\n",
      "products.txt: Google Pixel, $799.00, Google Pixel smartphones offer a pure Android experience with regular updates and exclusive features. They come with high-quality cameras that excel in low-light conditions, fast processors, and high-resolution displays. The Pixel's integration with Google services makes it a great choice for users who rely on Google's ecosystem.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = search_client.search(\n",
    "        user_question,\n",
    "        top=5, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"embedding\")],\n",
    "        # query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\".join([f\"{doc['sourcefile']}: {doc['content']}\\n\" for doc in r])\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(question):\n",
    "    r = search_client.search(\n",
    "            question,\n",
    "            top=5, \n",
    "            vector_queries=[\n",
    "                    VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"embedding\")],\n",
    "            # query_type=\"semantic\",\n",
    "            semantic_configuration_name=\"default\")\n",
    "\n",
    "    sources = \"\\n\".join([f\"{doc['sourcefile']}: {doc['content']}\\n\" for doc in r])\n",
    "\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(messages, question):\n",
    "    clone_messages = list(messages)\n",
    "    clone_messages.append({\"role\": \"user\", \"content\": f\"This is the user question: {question}. Based on the history and current question, generate the query in max 20 words to search in the knowledge base, don't explain more.\"})\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "        temperature=0.7,\n",
    "        messages=clone_messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send question and documents to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerated query: Customer question about available products and services.\n",
      "Human > hi\n",
      "Bot > Hello! How can I assist you today?\n",
      "\tGenerated query: Available smartphones and their features along with prices.\n",
      "Human > \n",
      "Bot > Hi! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Assistant helps answer customer's questions about the available products. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below.\n",
    "Each source has a name followed by colon and the actual information, include the source name for each fact you use.\n",
    "Use square brackets to reference the source, for example [info1.txt].\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
    "\n",
    "while(True):\n",
    "    sleep(1)\n",
    "    question = input()\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    query = generate_query(messages=messages, question=question)\n",
    "    print(f\"\\tGenerated query: {query}\")\n",
    "\n",
    "    sources = search(question=query)\n",
    "    print(\"Human > \" + question)\n",
    "\n",
    "    USER_MESSAGE = question + \"\\nSources: \" + sources\n",
    "    messages.append( {\"role\": \"user\", \"content\": USER_MESSAGE})\n",
    "    # Now we can use the matches to generate a response\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "        temperature=0.7,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    print(\"Bot > \" + answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_design_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
